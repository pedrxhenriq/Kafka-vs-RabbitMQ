from kafka import KafkaConsumer
import json
import time
import statistics

def kafka_latency_consumer():
    """
    Consumer Kafka para medir lat√™ncia end-to-end.
    
    Fluxo de timestamps:
    - T0: Cria√ß√£o da mensagem no producer (vem na mensagem)
    - T3: Recebimento da mensagem RAW (antes de processar)
    - T4: Ap√≥s desserializa√ß√£o JSON
    
    IMPORTANTE: value_deserializer=None para capturar T3 ANTES da desserializa√ß√£o!
    """
    
    topic_name = 'latency_test'
    
    print("=" * 60)
    print("KAFKA - CONSUMER DE TESTE DE LAT√äNCIA")
    print("=" * 60)
    print(f"Conectando ao Kafka e inscrevendo no t√≥pico '{topic_name}'...\n")
    
    # === CONFIGURAR CONSUMER ===
    # value_deserializer=None para desserializar manualmente
    consumer = KafkaConsumer(
        topic_name,
        bootstrap_servers=['localhost:9092'],
        auto_offset_reset='earliest',  # Ler desde o in√≠cio do t√≥pico
        enable_auto_commit=True,  # Commit autom√°tico de offsets
        group_id='latency_test_group',  # Grupo de consumo √∫nico
        value_deserializer=None,  # ‚Üê N√ÉO deserializar automaticamente
        consumer_timeout_ms=30000  # Timeout de 30s se n√£o houver mensagens
    )
    
    # Estruturas para armazenar dados
    latencies = []
    detailed_data = []
    
    print("üéß Aguardando mensagens...")
    print(f"üìç Parti√ß√µes atribu√≠das: {consumer.assignment()}\n")
    
    # === CONSUMIR MENSAGENS ===
    try:
        for message in consumer:
            # T3: Timestamp de recebimento da mensagem RAW (ANTES de qualquer processamento)
            t3_receive_raw = time.time() * 1000
            
            # T4: Desserializa√ß√£o manual (agora controlamos quando acontece)
            t4_before_deserialize = time.time() * 1000
            
            # Desserializar manualmente (message.value √© bytes)
            data = json.loads(message.value.decode('utf-8'))
            
            t4_after_deserialize = time.time() * 1000
            
            # T0: Recuperar timestamp de quando a mensagem foi criada no producer
            t0_creation = data['timestamp_ms']
            
            # Calcular lat√™ncias
            end_to_end_latency = t3_receive_raw - t0_creation  # Lat√™ncia total (sem desserializa√ß√£o)
            deserialization_time = t4_after_deserialize - t4_before_deserialize
            total_with_processing = t4_after_deserialize - t0_creation  # Com desserializa√ß√£o
            
            # Armazenar lat√™ncia end-to-end (sem desserializa√ß√£o)
            latencies.append(end_to_end_latency)
            
            # Armazenar dados detalhados para an√°lise posterior
            detailed_data.append({
                'message_id': data['id'],
                't0_creation_producer': t0_creation,
                't3_receive_raw_consumer': t3_receive_raw,
                't4_after_deserialize': t4_after_deserialize,
                'latency_end_to_end_ms': end_to_end_latency,
                'deserialization_time_ms': deserialization_time,
                'total_with_processing_ms': total_with_processing,
                'partition': message.partition,
                'offset': message.offset,
                'timestamp_iso': data['timestamp']
            })
            
            print(f"üì® Mensagem {data['id']:3d} | "
                  f"Lat√™ncia: {end_to_end_latency:6.2f} ms | "
                  f"Desserializa√ß√£o: {deserialization_time:.3f} ms | "
                  f"Partition: {message.partition} | Offset: {message.offset}")
            
            # Parar ap√≥s 100 mensagens
            if len(latencies) >= 100:
                break
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Timeout ou erro: {e}")
    
    # Fechar consumer
    consumer.close()
    
    # === CALCULAR ESTAT√çSTICAS ===
    if latencies:
        print("\n" + "=" * 60)
        print("RESULTADOS KAFKA - LAT√äNCIA END-TO-END")
        print("=" * 60)
        print(f"üìä Total de mensagens: {len(latencies)}")
        print(f"‚è±Ô∏è  Lat√™ncia m√©dia: {statistics.mean(latencies):.2f} ms")
        print(f"‚ö° Lat√™ncia m√≠nima: {min(latencies):.2f} ms")
        print(f"üêå Lat√™ncia m√°xima: {max(latencies):.2f} ms")
        print(f"üìà Mediana: {statistics.median(latencies):.2f} ms")
        print(f"üìä Desvio padr√£o: {statistics.stdev(latencies):.2f} ms")
        
        # Calcular percentis
        sorted_latencies = sorted(latencies)
        p50 = sorted_latencies[int(len(sorted_latencies) * 0.50)]
        p90 = sorted_latencies[int(len(sorted_latencies) * 0.90)]
        p95 = sorted_latencies[int(len(sorted_latencies) * 0.95)]
        p99 = sorted_latencies[int(len(sorted_latencies) * 0.99)]
        
        print(f"\nüìä Percentis:")
        print(f"   P50: {p50:.2f} ms")
        print(f"   P90: {p90:.2f} ms")
        print(f"   P95: {p95:.2f} ms")
        print(f"   P99: {p99:.2f} ms")
        print("=" * 60)
        
        # === SALVAR RESULTADOS EM ARQUIVO ===
        with open('kafka_latency_results.txt', 'w', encoding='utf-8') as f:
            # Cabe√ßalho explicativo
            f.write("=" * 70 + "\n")
            f.write("KAFKA - RELAT√ìRIO DE LAT√äNCIA END-TO-END\n")
            f.write("=" * 70 + "\n\n")
            
            f.write("üìñ EXPLICA√á√ÉO DA MEDI√á√ÉO:\n")
            f.write("-" * 70 + "\n")
            f.write("Este teste mede a LAT√äNCIA END-TO-END, que inclui:\n\n")
            f.write("  T0 ‚Üí Cria√ß√£o da mensagem no PRODUCER\n")
            f.write("       - Marca o timestamp antes da serializa√ß√£o JSON\n")
            f.write("       - Armazenado no campo 'timestamp_ms' da mensagem\n\n")
            f.write("  T1 ‚Üí Serializa√ß√£o JSON no producer\n")
            f.write("       - Convers√£o do dict Python para JSON bytes\n")
            f.write("       - Feita automaticamente pelo value_serializer\n\n")
            f.write("  T2 ‚Üí Envio pela rede + Processamento no Kafka\n")
            f.write("       - Transmiss√£o TCP/IP (localhost)\n")
            f.write("       - Persist√™ncia em disco (acks='all')\n")
            f.write("       - Replica√ß√£o entre brokers (se houver r√©plicas)\n")
            f.write("       - Armazenamento em parti√ß√£o/offset\n\n")
            f.write("  T3 ‚Üí Recebimento RAW no CONSUMER\n")
            f.write("       - Timestamp capturado ANTES da desserializa√ß√£o\n")
            f.write("       - Este √© o ponto final da medi√ß√£o\n")
            f.write("       - IMPORTANTE: value_deserializer=None para controlar isso!\n\n")
            f.write("  T4 ‚Üí Desserializa√ß√£o JSON no consumer\n")
            f.write("       - N√ÉO inclu√≠do na lat√™ncia end-to-end\n")
            f.write("       - Desserializa√ß√£o manual com json.loads()\n")
            f.write("       - Medido separadamente para an√°lise\n\n")
            f.write("LAT√äNCIA END-TO-END = T3 - T0\n")
            f.write("(Tempo total desde cria√ß√£o at√© recebimento, sem processamento)\n")
            f.write("=" * 70 + "\n\n")
            
            # Resumo estat√≠stico
            f.write("üìä RESUMO ESTAT√çSTICO\n")
            f.write("-" * 70 + "\n")
            f.write(f"Total de mensagens: {len(latencies)}\n")
            f.write(f"Lat√™ncia m√©dia: {statistics.mean(latencies):.2f} ms\n")
            f.write(f"Lat√™ncia m√≠nima: {min(latencies):.2f} ms\n")
            f.write(f"Lat√™ncia m√°xima: {max(latencies):.2f} ms\n")
            f.write(f"Mediana: {statistics.median(latencies):.2f} ms\n")
            f.write(f"Desvio padr√£o: {statistics.stdev(latencies):.2f} ms\n")
            f.write(f"\nPercentis:\n")
            f.write(f"  P50: {p50:.2f} ms\n")
            f.write(f"  P90: {p90:.2f} ms\n")
            f.write(f"  P95: {p95:.2f} ms\n")
            f.write(f"  P99: {p99:.2f} ms\n")
            f.write("\n" + "=" * 70 + "\n\n")
            
            # Dados detalhados em formato tabular
            f.write("üìã DADOS DETALHADOS (FORMATO DATAFRAME)\n")
            f.write("-" * 70 + "\n")
            f.write(f"{'ID':>4} | {'T0_Creation':>15} | {'T3_Receive':>15} | "
                   f"{'T4_Deserial':>15} | {'Latency':>10} | {'Deserial':>10} | "
                   f"{'Total':>10} | {'Part':>4} | {'Offset':>6}\n")
            f.write("-" * 70 + "\n")
            
            for data in detailed_data:
                f.write(f"{data['message_id']:4d} | "
                       f"{data['t0_creation_producer']:15.3f} | "
                       f"{data['t3_receive_raw_consumer']:15.3f} | "
                       f"{data['t4_after_deserialize']:15.3f} | "
                       f"{data['latency_end_to_end_ms']:10.3f} | "
                       f"{data['deserialization_time_ms']:10.3f} | "
                       f"{data['total_with_processing_ms']:10.3f} | "
                       f"{data['partition']:4d} | "
                       f"{data['offset']:6d}\n")
            
            f.write("\n" + "=" * 70 + "\n")
            f.write("LEGENDA:\n")
            f.write("  ID         = Identificador da mensagem\n")
            f.write("  T0_Creation = Timestamp de cria√ß√£o no producer (ms)\n")
            f.write("  T3_Receive  = Timestamp de recebimento RAW no consumer (ms)\n")
            f.write("  T4_Deserial = Timestamp ap√≥s desserializa√ß√£o (ms)\n")
            f.write("  Latency     = Lat√™ncia end-to-end SEM desserializa√ß√£o (ms)\n")
            f.write("  Deserial    = Tempo de desserializa√ß√£o JSON (ms)\n")
            f.write("  Total       = Tempo total COM desserializa√ß√£o (ms)\n")
            f.write("  Part        = Parti√ß√£o do Kafka onde a mensagem foi armazenada\n")
            f.write("  Offset      = Offset da mensagem na parti√ß√£o\n")
            f.write("=" * 70 + "\n")
        
        print(f"\nüíæ Resultados salvos em 'kafka_latency_results.txt'")
    
    else:
        print("\n‚ö†Ô∏è  Nenhuma mensagem foi recebida!")
        print("Verifique se:")
        print("  1. O Kafka est√° rodando (localhost:9092)")
        print("  2. O producer foi executado antes")
        print("  3. O t√≥pico 'latency_test' existe")

if __name__ == "__main__":
    kafka_latency_consumer()
